[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Skrub blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "posts/BLOG ARTICLE-Copy1 (2).html",
    "href": "posts/BLOG ARTICLE-Copy1 (2).html",
    "title": "Skrub blog",
    "section": "",
    "text": "SKRUB : A Python library for cleaning, structuring, and visualizing tabular data\nINTRODUCTION\nHow to deal with messy data Missing values, inconsistent formats, and unstructured information slow down data analysis? here skrub comes in picture! skrub is a powerful Python library designed to clean, structure, and prepare tabular data efficiently. In this guide, we’ll explore its key features\nskrub makes cleaning, organizing, and visualizing messy tables easier and faster\nData Cleaning – Removes inconsistencies, trims spaces, and fixes column names.\nHandling Missing Data – Easily fills missing values.\nDataset Merging– Intelligently links datasets, even with slight variations.\nQuick Insights– Generates structured data for visualization & analysis.\nWHY SKRUB?\nAssembling Tables with Precision:Skrub excels at joining tables on keys of different types, including string, numerical, and datetime, with an impressive ability to handle imprecise correspondences.\nFuzzy Joining for Seamless Integration: selects the type of fuzzy matching based on column types, producing a similarity score for easy identification of less-than-perfect matches\nAdvanced Analysis Made Simple:Skrub takes table joining to the next level with features like Joiner, AggJoiner, and AggTarget.\nEfficient Column Selection in Pipelines:Apart from joins, skrub also facilitates column selection within a pipeline, allowing data scientists to choose and discard columns dynamically.\nINSTALLATION PROCESS\n\npip install skrub\n\nRequirement already satisfied: skrub in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\nRequirement already satisfied: numpy&gt;=1.23.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.1)\nRequirement already satisfied: packaging&gt;=23.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (24.2)\nRequirement already satisfied: pandas&gt;=1.5.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.3)\nRequirement already satisfied: scikit-learn&gt;=1.2.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.6.1)\nRequirement already satisfied: scipy&gt;=1.9.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.15.2)\nRequirement already satisfied: jinja2&gt;=3.1.2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.1.5)\nRequirement already satisfied: matplotlib&gt;=3.4.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.10.0)\nRequirement already satisfied: requests&gt;=2.25.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.32.3)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2&gt;=3.1.2-&gt;skrub) (3.0.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (4.55.3)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (1.4.8)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (3.2.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas&gt;=1.5.3-&gt;skrub) (2025.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas&gt;=1.5.3-&gt;skrub) (2025.1)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (3.4.1)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (2025.1.31)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn&gt;=1.2.1-&gt;skrub) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn&gt;=1.2.1-&gt;skrub) (3.5.0)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&gt;=3.4.3-&gt;skrub) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\npip install --upgrade skrub\n\nRequirement already satisfied: skrub in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\nRequirement already satisfied: numpy&gt;=1.23.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.1)\nRequirement already satisfied: packaging&gt;=23.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (24.2)\nRequirement already satisfied: pandas&gt;=1.5.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.3)\nRequirement already satisfied: scikit-learn&gt;=1.2.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.6.1)\nRequirement already satisfied: scipy&gt;=1.9.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.15.2)\nRequirement already satisfied: jinja2&gt;=3.1.2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.1.5)\nRequirement already satisfied: matplotlib&gt;=3.4.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.10.0)\nRequirement already satisfied: requests&gt;=2.25.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.32.3)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2&gt;=3.1.2-&gt;skrub) (3.0.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (4.55.3)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (1.4.8)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (3.2.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib&gt;=3.4.3-&gt;skrub) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas&gt;=1.5.3-&gt;skrub) (2025.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas&gt;=1.5.3-&gt;skrub) (2025.1)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (3.4.1)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&gt;=2.25.0-&gt;skrub) (2025.1.31)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn&gt;=1.2.1-&gt;skrub) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn&gt;=1.2.1-&gt;skrub) (3.5.0)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&gt;=3.4.3-&gt;skrub) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\nUSING SKRUB\n1.HANDLING MISSING DATAFILES:\nWe always find issues when cleaning data is dealing with missing or NaN values. With Skrub, you can fill or drop these missing values with just a few lines of code.\nfor example consider this code:\n\n#filling missing values\nimport pandas as pd\n\n\ndata = {\n    'Name': ['Alice', 'Bob', None, 'Eve'],\n    'Age': [25, None, 22, 29],\n    'City': ['New York', 'Paris', None, None]\n}\n\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25.0\nNew York\n\n\n1\nBob\nNaN\nParis\n\n\n2\nNone\n22.0\nNone\n\n\n3\nEve\n29.0\nNone\n\n\n\n\n\n\n\nwe can use skrub’s missing module to fill the missing values. For example, to fill numerical columns with the mean and categorical columns with the mode, we can use th following code:\n\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom skrub import TableVectorizer  # Correct import\n\n# Sample data with missing values\ndata = {\n    'Name': ['Alice', 'Bob', None, 'Eve'],\n    'Age': [25, None, 22, 29],\n    'City': ['New York', 'Paris', None, None]\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\nprint(\"Original Data:\")\nprint(df)\n\n# Fill missing values correctly (avoid FutureWarning)\ndf['Age'] = df['Age'].fillna(df['Age'].mean())  # Filling missing Age with the mean\ndf['Name'] = df['Name'].fillna('Unknown')\ndf['City'] = df['City'].fillna('Unknown')\n\nprint(\"\\nData After Filling Missing Values:\")\nprint(df)\n\n# Standardize the 'Age' column\nscaler = StandardScaler()\ndf['Age'] = scaler.fit_transform(df[['Age']])\n\nprint(\"\\nData After Standardizing 'Age' Column:\")\nprint(df)\n\n# Vectorize the table (convert categorical data into numerical featur\n\nOriginal Data:\n    Name   Age      City\n0  Alice  25.0  New York\n1    Bob   NaN     Paris\n2   None  22.0      None\n3    Eve  29.0      None\n\nData After Filling Missing Values:\n      Name        Age      City\n0    Alice  25.000000  New York\n1      Bob  25.333333     Paris\n2  Unknown  22.000000   Unknown\n3      Eve  29.000000   Unknown\n\nData After Standardizing 'Age' Column:\n      Name       Age      City\n0    Alice -0.134231  New York\n1      Bob  0.000000     Paris\n2  Unknown -1.342312   Unknown\n3      Eve  1.476543   Unknown\n\n\nThe age column is replaced with its mean value.\nthe missing Name and City values are replaced with the string ‘Unknown’.\nTableVectorizer handles the categorical features and converts them into binary features (one-hot encoding). Output The cleaned data is now numerical, and we can see how missing values were handled.\n2.STANDARDIZING DATA\nskrub can be useful standardize numerical data, by making sure that values are consistent across the dataset. For example, if we have a column of Age values with a large range, we can scale it between 0 and 1 using normalization or standardization techniques.\nfor example analyze the code below\n\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom skrub._table_vectorizer import TableVectorizer\n\n# Sample data with missing values\ndata = {\n    'Name': ['Alice', 'Bob', None, 'Eve'],\n    'Age': [25, None, 22, 29],\n    'City': ['New York', 'Paris', None, None]\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\nprint(\"Original Data:\")\nprint(df)\n\n# Fill missing values correctly (avoid FutureWarning)\ndf['Age'] = df['Age'].fillna(df['Age'].mean())  # Filling missing Age with the mean\ndf['Name'] = df['Name'].fillna('Unknown')\ndf['City'] = df['City'].fillna('Unknown')\n\nprint(\"\\nData After Filling Missing Values:\")\nprint(df)\n\n# Standardize the 'Age' column\nscaler = StandardScaler()\ndf['Age'] = scaler.fit_transform(df[['Age']])\n\nprint(\"\\nData After Standardizing 'Age' Column:\")\nprint(df)\n\n# Vectorize the table (convert categorical data into numerical features)\nvectorizer = TableVectorizer()\ndf_vectorized = vectorizer.fit_transform(df)\n\nprint(\"\\nVectorized Data:\")\nprint(df_vectorized)\n\nOriginal Data:\n    Name   Age      City\n0  Alice  25.0  New York\n1    Bob   NaN     Paris\n2   None  22.0      None\n3    Eve  29.0      None\n\nData After Filling Missing Values:\n      Name        Age      City\n0    Alice  25.000000  New York\n1      Bob  25.333333     Paris\n2  Unknown  22.000000   Unknown\n3      Eve  29.000000   Unknown\n\nData After Standardizing 'Age' Column:\n      Name       Age      City\n0    Alice -0.134231  New York\n1      Bob  0.000000     Paris\n2  Unknown -1.342312   Unknown\n3      Eve  1.476543   Unknown\n\nVectorized Data:\n   Name_Alice  Name_Bob  Name_Eve  Name_Unknown       Age  City_New York  \\\n0         1.0       0.0       0.0           0.0 -0.134231            1.0   \n1         0.0       1.0       0.0           0.0  0.000000            0.0   \n2         0.0       0.0       0.0           1.0 -1.342312            0.0   \n3         0.0       0.0       1.0           0.0  1.476543            0.0   \n\n   City_Paris  City_Unknown  \n0         0.0           0.0  \n1         1.0           0.0  \n2         0.0           1.0  \n3         0.0           1.0  \n\n\nThe code fills missing values in the Age, Name, and City columns, then standardizes the Age column using StandardScaler. Afterward, it uses TableVectorizer to convert the entire dataframe into numerical features for machine learning.\n3.TRANSFORMING CATEGEORICAL VARIABLES:\nCategorical variables, such as names of cities or product categories, must be encoded into numerical values to be applied it machine learning algorithms.\nSkrub makes this easy with the TableVectorizer, which handles one-hot encoding and other encoding methods automatically.\noberse the code below.\n\n# Use TableVectorizer to transform categorical columns\nvectorizer = TableVectorizer()\ndf_transformed = vectorizer.fit_transform(df)\n\nprint(\"\\nTransformed Data (Categorical Encoded):\")\nprint(df_transformed)\n\n\nTransformed Data (Categorical Encoded):\n   Name_Alice  Name_Bob  Name_Eve  Name_Unknown       Age  City_New York  \\\n0         1.0       0.0       0.0           0.0 -0.134231            1.0   \n1         0.0       1.0       0.0           0.0  0.000000            0.0   \n2         0.0       0.0       0.0           1.0 -1.342312            0.0   \n3         0.0       0.0       1.0           0.0  1.476543            0.0   \n\n   City_Paris  City_Unknown  \n0         0.0           0.0  \n1         1.0           0.0  \n2         0.0           1.0  \n3         0.0           1.0  \n\n\nThe code uses TableVectorizer to change text data (like ‘City’ and ‘Gender’) into numbers. It creates new columns for each category, with 1 or 0 to show if that category is present. This helps turn the data into a form that computers can understand for analysis.\n4.MERGING SIMILAR TEXT DATA\nIf we have a messy text (for example “NewYork” vs “New Yor”), Skrub will match and merge them as shown below:\n\nfrom skrub import fuzzy_join\nimport pandas as pd\n\n# Sample data: Customer names with typos\ndf1 = pd.DataFrame({'Name': ['John Doe', 'Alice W.', 'Eve Smith']})\ndf2 = pd.DataFrame({'Name': ['Jon Doe', 'Eve s.','Alice '], 'Purchase': [100, 200, 150]})\n\n# Use Skrub to match similar names\nmerged_df = fuzzy_join(df1, df2, on='Name')\n\nprint(\"\\nFuzzy Matched Data:\\n\", merged_df)\n\n\nFuzzy Matched Data:\n         Name Name__skrub_d4fa04a9__  Purchase\n0   John Doe                Jon Doe       100\n1   Alice W.                 Alice        150\n2  Eve Smith                 Eve s.       200\n\n\nThe “fuzzy join” recipe is dedicated to joins between two datasets when join keys don’t match exactly.\nIt works by calculating a distance chosen by user and then comparing it to a threshold. DSS handles inner, left, right or outer joins.\n5.DETECTION AND FILTERING OUTLIERS\nThere are 4 ways to detect outliers:\n1.Sorting method\n2.Data visualization method\n3.Statistical tests (z scores)\n4.Interquartile range method\nTo understand in detail we can use the Interquartile Range (IQR) method.\nfirst of all lets analyse the code below:\n\nimport pandas as pd\nimport numpy as np\nfrom skrub import TableVectorizer\n\n# Sample data with an outlier\ndata = {'Salary': [30000, 50000, 70000, 999000]}  \n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Detect and remove outliers using IQR method\nQ1 = df['Salary'].quantile(0.25)\nQ3 = df['Salary'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define the lower and upper bounds\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Remove outliers\ndf_cleaned = df[(df['Salary'] &gt;= lower_bound) & (df['Salary'] &lt;= upper_bound)]\n\nprint(\"Original Data:\")\nprint(df)\n\nprint(\"\\nCleaned Data (Outliers Removed):\")\nprint(df_cleaned)\n\nOriginal Data:\n   Salary\n0   30000\n1   50000\n2   70000\n3  999000\n\nCleaned Data (Outliers Removed):\n   Salary\n0   30000\n1   50000\n2   70000\n\n\nThe interquartile range (IQR) tells you the range of the middle half of your dataset. You can use the IQR to create “fences” around your data and then define outliers as any values that fall outside those fences.\nThis method is helpful if you have a few values on the extreme ends of your dataset.\nInterquartile range method\nSort your data from low to high\nIdentify the first quartile (Q1), the median, and the third quartile (Q3).\nCalculate your IQR = Q3 – Q1\nCalculate your upper fence = Q3 + (1.5 * IQR)\nCalculate your lower fence = Q1 – (1.5 * IQR)\nUse your fences to highlight any outliers, all values that fall outside your fences.\nYour outliers are any values greater than your upper fence or less than your lower fence.\nCONCLUSION: In the end, skrub has many uses in handling data in python.it helps in simplifying messy data along with organizing it.it helps the users in cleaning the data efficiently with minimum effort. This saves a lot of time along with preserving of accuracy and consistancy.Without tools like Skrub, cleaning large datasets manually can be slow and has higher probality of getting errors. Skrub helps with tasks like filling missing values, fixing inconsistencies, and standardizing formats.\nREFERENCES:\nhttps://blog.stackademic.com/unleashing-the-power-of-skrub-revolutionizing-table-preparation-for-machine-learning-cdfe9dee8804\nhttps://doc.dataiku.com/dss/latest/other_recipes/fuzzy-join.html\nhttps://www.scribbr.com/statistics/outliers/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Skrub",
    "section": "",
    "text": "By Ankita Kushwaha 24110043 Jakku Niharika sri 24110143 Lingala Hasini 24110186"
  }
]